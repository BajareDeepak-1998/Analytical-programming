{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import requests\n",
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "import plotly.express as px\n",
    "import nest_asyncio\n",
    "from dash import Dash, dcc, html\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data into mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "Records inserted into MondgoDB sucessfully!!\n",
      "No more data to fetch.\n",
      "Data loading completed!!!!.\n"
     ]
    }
   ],
   "source": [
    "# MongoDB Connection\n",
    "client = MongoClient(\"mongodb+srv://deepakbajare0602:iSP0ylPUGnAtrn5G@datacluster1.hlnws.mongodb.net/\")  # MongoDB URI\n",
    "db = client[\"AirQualityDB\"]  # Database name\n",
    "collection = db[\"AirQualityData\"]  # Collection name\n",
    "\n",
    "# API URL for the dataset\n",
    "base_url = \"https://data.cityofnewyork.us/resource/c3uy-2p5r.json\"\n",
    "\n",
    "# Define the query parameters (filter for records from 2023 onward)\n",
    "params = {\n",
    "    \"$limit\": 1000  # Fetch 1000 records per API call\n",
    "}\n",
    "\n",
    "# Loop to fetch and insert data in batches\n",
    "offset = 0\n",
    "batch_size = 1000\n",
    "while True:\n",
    "    params[\"$offset\"] = offset\n",
    "    \n",
    "    # Send GET request to the API\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # If there is no more data, break the loop\n",
    "        if not data:\n",
    "            print(\"No more data to fetch.\")\n",
    "            break\n",
    "        \n",
    "        # Insert data into MongoDB in batch of 1000\n",
    "        try:\n",
    "            if isinstance(data, list):\n",
    "                collection.insert_many(data)\n",
    "                # print(f\"Inserted {len(data)} records into MongoDB, offset: {offset}\")\n",
    "            else:\n",
    "                print(f\"Unexpected data format at offset {offset}: {type(data)} \")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting data: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            print(\"Records inserted into MondgoDB sucessfully!!\")    \n",
    "        \n",
    "        # Increment offset for the next batch\n",
    "        offset += batch_size\n",
    "        \n",
    "        # Add a small delay between requests to avoid hitting rate limits\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "        break\n",
    "\n",
    "print(\"Data loading completed!!!!.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the Data from mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: Index(['_id', 'unique_id', 'indicator_id', 'name', 'measure', 'measure_info',\n",
      "       'geo_type_name', 'geo_join_id', 'geo_place_name', 'time_period',\n",
      "       'start_date', 'data_value'],\n",
      "      dtype='object')\n",
      "Selected columns: ['unique_id', 'indicator_id', 'name', 'measure', 'measure_info', 'geo_type_name', 'geo_join_id', 'geo_place_name', 'time_period', 'start_date', 'data_value']\n",
      "Data saved to air_quality_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Fetch data from MongoDB\n",
    "data = collection.find()\n",
    "\n",
    "# Convert the cursor to a list of dictionaries (JSON format)\n",
    "data_list = list(data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Debug: Print the available columns\n",
    "print(\"Available columns:\", df.columns)\n",
    "\n",
    "# Define required columns (normalize to lowercase)\n",
    "required_columns = ['unique_id', 'indicator_id', 'name', 'measure', 'measure_info',\n",
    "                    'geo_type_name', 'geo_join_id', 'geo_place_name', 'time_period',\n",
    "                    'start_date', 'data_value']\n",
    "\n",
    "# Normalize column names in DataFrame and required_columns\n",
    "df.columns = df.columns.str.lower()\n",
    "required_columns = [col.lower() for col in required_columns]\n",
    "\n",
    "# Filter only available columns\n",
    "available_columns = [col for col in required_columns if col in df.columns]\n",
    "print(\"Selected columns:\", available_columns)\n",
    "\n",
    "# Select relevant columns\n",
    "airquality_df = df[available_columns]\n",
    "\n",
    "# Save to CSV\n",
    "airquality_df.to_csv(\"air_quality_dataset.csv\", index=False)\n",
    "print(\"Data saved to air_quality_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>indicator_id</th>\n",
       "      <th>name</th>\n",
       "      <th>measure</th>\n",
       "      <th>measure_info</th>\n",
       "      <th>geo_type_name</th>\n",
       "      <th>geo_join_id</th>\n",
       "      <th>geo_place_name</th>\n",
       "      <th>time_period</th>\n",
       "      <th>start_date</th>\n",
       "      <th>data_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>825967</td>\n",
       "      <td>375</td>\n",
       "      <td>Nitrogen dioxide (NO2)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>ppb</td>\n",
       "      <td>UHF34</td>\n",
       "      <td>104</td>\n",
       "      <td>Pelham - Throgs Neck</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823492</td>\n",
       "      <td>365</td>\n",
       "      <td>Fine particles (PM 2.5)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>mcg/m3</td>\n",
       "      <td>CD</td>\n",
       "      <td>307</td>\n",
       "      <td>Sunset Park (CD7)</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>827012</td>\n",
       "      <td>386</td>\n",
       "      <td>Ozone (O3)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>ppb</td>\n",
       "      <td>CD</td>\n",
       "      <td>313</td>\n",
       "      <td>Coney Island (CD13)</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>827081</td>\n",
       "      <td>386</td>\n",
       "      <td>Ozone (O3)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>ppb</td>\n",
       "      <td>UHF34</td>\n",
       "      <td>103</td>\n",
       "      <td>Fordham - Bronx Pk</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>827103</td>\n",
       "      <td>386</td>\n",
       "      <td>Ozone (O3)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>ppb</td>\n",
       "      <td>UHF42</td>\n",
       "      <td>503</td>\n",
       "      <td>Willowbrook</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>34.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>823211</td>\n",
       "      <td>365</td>\n",
       "      <td>Fine particles (PM 2.5)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>mcg/m3</td>\n",
       "      <td>CD</td>\n",
       "      <td>105</td>\n",
       "      <td>Midtown (CD5)</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>823241</td>\n",
       "      <td>365</td>\n",
       "      <td>Fine particles (PM 2.5)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>mcg/m3</td>\n",
       "      <td>UHF42</td>\n",
       "      <td>401</td>\n",
       "      <td>Long Island City - Astoria</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>825903</td>\n",
       "      <td>375</td>\n",
       "      <td>Nitrogen dioxide (NO2)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>ppb</td>\n",
       "      <td>UHF34</td>\n",
       "      <td>303</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>823337</td>\n",
       "      <td>365</td>\n",
       "      <td>Fine particles (PM 2.5)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>mcg/m3</td>\n",
       "      <td>Borough</td>\n",
       "      <td>2</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>827065</td>\n",
       "      <td>386</td>\n",
       "      <td>Ozone (O3)</td>\n",
       "      <td>Mean</td>\n",
       "      <td>ppb</td>\n",
       "      <td>UHF34</td>\n",
       "      <td>304</td>\n",
       "      <td>Upper West Side</td>\n",
       "      <td>Summer 2022</td>\n",
       "      <td>2022-06-01T00:00:00.000</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id indicator_id                     name measure measure_info  \\\n",
       "0    825967          375   Nitrogen dioxide (NO2)    Mean          ppb   \n",
       "1    823492          365  Fine particles (PM 2.5)    Mean       mcg/m3   \n",
       "2    827012          386               Ozone (O3)    Mean          ppb   \n",
       "3    827081          386               Ozone (O3)    Mean          ppb   \n",
       "4    827103          386               Ozone (O3)    Mean          ppb   \n",
       "5    823211          365  Fine particles (PM 2.5)    Mean       mcg/m3   \n",
       "6    823241          365  Fine particles (PM 2.5)    Mean       mcg/m3   \n",
       "7    825903          375   Nitrogen dioxide (NO2)    Mean          ppb   \n",
       "8    823337          365  Fine particles (PM 2.5)    Mean       mcg/m3   \n",
       "9    827065          386               Ozone (O3)    Mean          ppb   \n",
       "\n",
       "  geo_type_name geo_join_id              geo_place_name  time_period  \\\n",
       "0         UHF34         104        Pelham - Throgs Neck  Summer 2022   \n",
       "1            CD         307           Sunset Park (CD7)  Summer 2022   \n",
       "2            CD         313         Coney Island (CD13)  Summer 2022   \n",
       "3         UHF34         103          Fordham - Bronx Pk  Summer 2022   \n",
       "4         UHF42         503                 Willowbrook  Summer 2022   \n",
       "5            CD         105               Midtown (CD5)  Summer 2022   \n",
       "6         UHF42         401  Long Island City - Astoria  Summer 2022   \n",
       "7         UHF34         303                 East Harlem  Summer 2022   \n",
       "8       Borough           2                    Brooklyn  Summer 2022   \n",
       "9         UHF34         304             Upper West Side  Summer 2022   \n",
       "\n",
       "                start_date data_value  \n",
       "0  2022-06-01T00:00:00.000       12.0  \n",
       "1  2022-06-01T00:00:00.000        6.7  \n",
       "2  2022-06-01T00:00:00.000       37.7  \n",
       "3  2022-06-01T00:00:00.000       31.7  \n",
       "4  2022-06-01T00:00:00.000       34.8  \n",
       "5  2022-06-01T00:00:00.000        8.7  \n",
       "6  2022-06-01T00:00:00.000        7.2  \n",
       "7  2022-06-01T00:00:00.000       13.0  \n",
       "8  2022-06-01T00:00:00.000        6.3  \n",
       "9  2022-06-01T00:00:00.000       29.9  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airqulity un-structured data from mongoDb\n",
    "airquality_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the air_quality(108150, 11)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the Air-Quality data\n",
    "print(f\"shape of the air_quality{airquality_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108150 entries, 0 to 108149\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   unique_id       108150 non-null  object\n",
      " 1   indicator_id    108150 non-null  object\n",
      " 2   name            108150 non-null  object\n",
      " 3   measure         108150 non-null  object\n",
      " 4   measure_info    108150 non-null  object\n",
      " 5   geo_type_name   108150 non-null  object\n",
      " 6   geo_join_id     108096 non-null  object\n",
      " 7   geo_place_name  108096 non-null  object\n",
      " 8   time_period     108150 non-null  object\n",
      " 9   start_date      108150 non-null  object\n",
      " 10  data_value      108150 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info of the Air-Quality data\n",
    "airquality_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed null values\n",
      "Duplicates removed.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_airQuaility_dataset(airquality_df):\n",
    "    \n",
    "    # Handle Missing/Null Values\n",
    "    data_before_drop_null =  airquality_df.isnull().sum()\n",
    "    \n",
    "    # Drop rows with all missing/NULL values\n",
    "    airquality_df = airquality_df.dropna()\n",
    "\n",
    "    # Cheking Missing/Null values again\n",
    "    data_after_drop_null = airquality_df.isnull().sum()\n",
    "    print(\"Removed null values\")\n",
    "\n",
    "    # Cheking duplicate values\n",
    "    has_duplicates = airquality_df.duplicated().any()\n",
    "    if has_duplicates:\n",
    "        airquality_df = airquality_df.drop_duplicates()\n",
    "        print(\"Duplicates removed.\")\n",
    " \n",
    "    return airquality_df\n",
    "\n",
    "processed_airquality_df = preprocess_airQuaility_dataset(airquality_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17629, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_airquality_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loaded the NYPD Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYPD Data:\n",
      "    ARREST_KEY ARREST_DATE  PD_CD                   PD_DESC  KY_CD  \\\n",
      "0   281240883  01/28/2024  105.0         STRANGULATION 1ST  106.0   \n",
      "1   282884120  02/27/2024  263.0               ARSON 2,3,4  114.0   \n",
      "2   283137868  03/03/2024  109.0  ASSAULT 2,1,UNCLASSIFIED  106.0   \n",
      "3   287001362  05/16/2024  109.0  ASSAULT 2,1,UNCLASSIFIED  106.0   \n",
      "4   287829614  06/02/2024  105.0         STRANGULATION 1ST  106.0   \n",
      "5   280513565  01/14/2024  153.0                    RAPE 3  104.0   \n",
      "6   291269261  08/07/2024  157.0                    RAPE 1  104.0   \n",
      "7   280286274  01/10/2024  105.0         STRANGULATION 1ST  106.0   \n",
      "8   281035905  01/24/2024  777.0                    (null)    NaN   \n",
      "9   279805425  01/02/2024  109.0  ASSAULT 2,1,UNCLASSIFIED  106.0   \n",
      "\n",
      "        OFNS_DESC    LAW_CODE LAW_CAT_CD ARREST_BORO  ARREST_PRECINCT  \\\n",
      "0  FELONY ASSAULT  PL 1211200          F           Q              105   \n",
      "1           ARSON  PL 1501001          F           Q              107   \n",
      "2  FELONY ASSAULT  PL 1200502          F           B               48   \n",
      "3  FELONY ASSAULT  PL 1200512          F           S              121   \n",
      "4  FELONY ASSAULT  PL 1211200          F           Q              100   \n",
      "5            RAPE  PL 1302503          F           M               14   \n",
      "6            RAPE  PL 1303504          F           K               84   \n",
      "7  FELONY ASSAULT  PL 1211200          F           K               70   \n",
      "8          (null)  PL 1950200          F           K               67   \n",
      "9  FELONY ASSAULT  PL 1200502          F           Q              100   \n",
      "\n",
      "   JURISDICTION_CODE AGE_GROUP PERP_SEX       PERP_RACE  X_COORD_CD  \\\n",
      "0                  0     25-44        M           WHITE     1057545   \n",
      "1                 71     45-64        M           WHITE     1037489   \n",
      "2                  0     25-44        M           BLACK     1013900   \n",
      "3                  0     25-44        M           WHITE      938928   \n",
      "4                  0     25-44        M           BLACK     1039777   \n",
      "5                  0     18-24        M           BLACK      985764   \n",
      "6                  0     25-44        M  WHITE HISPANIC      988902   \n",
      "7                  0     25-44        M           BLACK      993690   \n",
      "8                  0     45-64        F           WHITE      997897   \n",
      "9                  0     25-44        M           BLACK     1035353   \n",
      "\n",
      "   Y_COORD_CD   Latitude  Longitude  \\\n",
      "0      207911  40.737043 -73.735514   \n",
      "1      206343  40.732881 -73.807899   \n",
      "2      250835  40.855109 -73.892818   \n",
      "3      168468  40.628967 -74.163275   \n",
      "4      155013  40.591980 -73.800066   \n",
      "5      213806  40.753533 -73.994537   \n",
      "6      192641  40.695439 -73.983225   \n",
      "7      172242  40.639436 -73.965983   \n",
      "8      175676  40.648859 -73.950820   \n",
      "9      152906  40.586222 -73.816011   \n",
      "\n",
      "                     New Georeferenced Column  \n",
      "0                POINT (-73.735514 40.737043)  \n",
      "1                POINT (-73.807899 40.732881)  \n",
      "2                POINT (-73.892818 40.855109)  \n",
      "3                POINT (-74.163275 40.628967)  \n",
      "4                 POINT (-73.800066 40.59198)  \n",
      "5  POINT (-73.9945368920152 40.7535327012632)  \n",
      "6  POINT (-73.9832253756043 40.6954388081238)  \n",
      "7                POINT (-73.965983 40.639436)  \n",
      "8                 POINT (-73.95082 40.648859)  \n",
      "9                POINT (-73.816011 40.586222)  \n",
      "\n",
      "NYPD Data: shape:\n",
      "(195447, 19)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195447 entries, 0 to 195446\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   ARREST_KEY                195447 non-null  int64  \n",
      " 1   ARREST_DATE               195447 non-null  object \n",
      " 2   PD_CD                     195441 non-null  float64\n",
      " 3   PD_DESC                   195447 non-null  object \n",
      " 4   KY_CD                     195421 non-null  float64\n",
      " 5   OFNS_DESC                 195447 non-null  object \n",
      " 6   LAW_CODE                  195447 non-null  object \n",
      " 7   LAW_CAT_CD                194338 non-null  object \n",
      " 8   ARREST_BORO               195447 non-null  object \n",
      " 9   ARREST_PRECINCT           195447 non-null  int64  \n",
      " 10  JURISDICTION_CODE         195447 non-null  int64  \n",
      " 11  AGE_GROUP                 195447 non-null  object \n",
      " 12  PERP_SEX                  195447 non-null  object \n",
      " 13  PERP_RACE                 195447 non-null  object \n",
      " 14  X_COORD_CD                195447 non-null  int64  \n",
      " 15  Y_COORD_CD                195447 non-null  int64  \n",
      " 16  Latitude                  195447 non-null  float64\n",
      " 17  Longitude                 195447 non-null  float64\n",
      " 18  New Georeferenced Column  195447 non-null  object \n",
      "dtypes: float64(4), int64(5), object(10)\n",
      "memory usage: 28.3+ MB\n",
      "NYPD Info:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_NYPD_data(url):\n",
    "          \n",
    "           #loading the data \n",
    "          nypd_df=pd.read_csv(url)\n",
    "\n",
    "          #Dispplaying the dataSet\n",
    "          nypd_data=nypd_df.head(10)\n",
    "          print(f\"NYPD Data:\\n {nypd_data}\\n\")\n",
    "          \n",
    "          #Displaying the shape of dataset\n",
    "          nypd_shape=nypd_df.shape\n",
    "          print(f\"NYPD Data: shape:\\n{nypd_shape}\\n\")\n",
    "\n",
    "          nypd_info=nypd_df.info()\n",
    "          print(f\"NYPD Info:\\n{nypd_info}\")\n",
    "\n",
    "url = \"/Users/deepakbajare/Documents/Projects/Dap/NYPD_Arrest_Data__Year_to_Date_.csv\"\n",
    "\n",
    "load_NYPD_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for NYPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before processing:\n",
      "ARREST_KEY                     0\n",
      "ARREST_DATE                    0\n",
      "PD_CD                          6\n",
      "PD_DESC                        0\n",
      "KY_CD                         26\n",
      "OFNS_DESC                      0\n",
      "LAW_CODE                       0\n",
      "LAW_CAT_CD                  1109\n",
      "ARREST_BORO                    0\n",
      "ARREST_PRECINCT                0\n",
      "JURISDICTION_CODE              0\n",
      "AGE_GROUP                      0\n",
      "PERP_SEX                       0\n",
      "PERP_RACE                      0\n",
      "X_COORD_CD                     0\n",
      "Y_COORD_CD                     0\n",
      "Latitude                       0\n",
      "Longitude                      0\n",
      "New Georeferenced Column       0\n",
      "dtype: int64\n",
      "Missing values after processing:\n",
      "ARREST_KEY                  0\n",
      "ARREST_DATE                 0\n",
      "PD_CD                       0\n",
      "PD_DESC                     0\n",
      "KY_CD                       0\n",
      "OFNS_DESC                   0\n",
      "LAW_CODE                    0\n",
      "LAW_CAT_CD                  0\n",
      "ARREST_BORO                 0\n",
      "ARREST_PRECINCT             0\n",
      "JURISDICTION_CODE           0\n",
      "AGE_GROUP                   0\n",
      "PERP_SEX                    0\n",
      "PERP_RACE                   0\n",
      "X_COORD_CD                  0\n",
      "Y_COORD_CD                  0\n",
      "Latitude                    0\n",
      "Longitude                   0\n",
      "New Georeferenced Column    0\n",
      "dtype: int64\n",
      "Duplicates found: False\n",
      "No duplicate rows found.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_NYPD_Arrest_Data__Year_to_Date(nypd_df):\n",
    "    # Checking and summarizing missing/null values before processing\n",
    "    print(\"Missing values before processing:\")\n",
    "    print(nypd_df.isnull().sum())\n",
    "\n",
    "    # Drop rows with all missing/NULL values\n",
    "    nypd_df = nypd_df.dropna()\n",
    "\n",
    "    # Checking and summarizing missing/null values after dropping\n",
    "    print(\"Missing values after processing:\")\n",
    "    print(nypd_df.isnull().sum())\n",
    "\n",
    "    # Checking for duplicate values\n",
    "    has_duplicates = nypd_df.duplicated().any()\n",
    "    print(f\"Duplicates found: {has_duplicates}\")\n",
    "    if has_duplicates:\n",
    "        nypd_df = nypd_df.drop_duplicates()\n",
    "        print(\"Duplicates removed.\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n",
    "    return nypd_df\n",
    "\n",
    "nypd_df = pd.read_csv(\"NYPD_Arrest_Data__Year_to_Date_.csv\")\n",
    "processed_nypd_df = preprocess_NYPD_Arrest_Data__Year_to_Date(nypd_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194312, 19)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_nypd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ARREST_KEY', 'ARREST_DATE', 'PD_CD', 'PD_DESC', 'KY_CD', 'OFNS_DESC',\n",
       "       'LAW_CODE', 'LAW_CAT_CD', 'ARREST_BORO', 'ARREST_PRECINCT',\n",
       "       'JURISDICTION_CODE', 'AGE_GROUP', 'PERP_SEX', 'PERP_RACE', 'X_COORD_CD',\n",
       "       'Y_COORD_CD', 'Latitude', 'Longitude', 'New Georeferenced Column'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_nypd_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime_Data_from_2020_to_Present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime_dataset:\n",
      "        DR_NO               Date Rptd                DATE OCC  TIME OCC  AREA  \\\n",
      "0  190326475  03/01/2020 12:00:00 AM  03/01/2020 12:00:00 AM      2130     7   \n",
      "1  200106753  02/09/2020 12:00:00 AM  02/08/2020 12:00:00 AM      1800     1   \n",
      "2  200320258  11/11/2020 12:00:00 AM  11/04/2020 12:00:00 AM      1700     3   \n",
      "3  200907217  05/10/2023 12:00:00 AM  03/10/2020 12:00:00 AM      2037     9   \n",
      "4  200412582  09/09/2020 12:00:00 AM  09/09/2020 12:00:00 AM       630     4   \n",
      "\n",
      "    AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
      "0    Wilshire          784         1     510   \n",
      "1     Central          182         1     330   \n",
      "2   Southwest          356         1     480   \n",
      "3    Van Nuys          964         1     343   \n",
      "4  Hollenbeck          413         1     510   \n",
      "\n",
      "                                Crm Cd Desc  ... Status   Status Desc  \\\n",
      "0                          VEHICLE - STOLEN  ...     AA  Adult Arrest   \n",
      "1                     BURGLARY FROM VEHICLE  ...     IC   Invest Cont   \n",
      "2                             BIKE - STOLEN  ...     IC   Invest Cont   \n",
      "3  SHOPLIFTING-GRAND THEFT ($950.01 & OVER)  ...     IC   Invest Cont   \n",
      "4                          VEHICLE - STOLEN  ...     IC   Invest Cont   \n",
      "\n",
      "  Crm Cd 1 Crm Cd 2  Crm Cd 3 Crm Cd 4  \\\n",
      "0    510.0    998.0       NaN      NaN   \n",
      "1    330.0    998.0       NaN      NaN   \n",
      "2    480.0      NaN       NaN      NaN   \n",
      "3    343.0      NaN       NaN      NaN   \n",
      "4    510.0      NaN       NaN      NaN   \n",
      "\n",
      "                                   LOCATION Cross Street      LAT       LON  \n",
      "0   1900 S  LONGWOOD                     AV          NaN  34.0375 -118.3506  \n",
      "1   1000 S  FLOWER                       ST          NaN  34.0444 -118.2628  \n",
      "2   1400 W  37TH                         ST          NaN  34.0210 -118.3002  \n",
      "3  14000    RIVERSIDE                    DR          NaN  34.1576 -118.4387  \n",
      "4                          200 E  AVENUE 28          NaN  34.0820 -118.2130  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "crime_data shape:\n",
      "(986873, 28)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 986873 entries, 0 to 986872\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   DR_NO           986873 non-null  int64  \n",
      " 1   Date Rptd       986873 non-null  object \n",
      " 2   DATE OCC        986873 non-null  object \n",
      " 3   TIME OCC        986873 non-null  int64  \n",
      " 4   AREA            986873 non-null  int64  \n",
      " 5   AREA NAME       986873 non-null  object \n",
      " 6   Rpt Dist No     986873 non-null  int64  \n",
      " 7   Part 1-2        986873 non-null  int64  \n",
      " 8   Crm Cd          986873 non-null  int64  \n",
      " 9   Crm Cd Desc     986873 non-null  object \n",
      " 10  Mocodes         839400 non-null  object \n",
      " 11  Vict Age        986873 non-null  int64  \n",
      " 12  Vict Sex        846266 non-null  object \n",
      " 13  Vict Descent    846254 non-null  object \n",
      " 14  Premis Cd       986857 non-null  float64\n",
      " 15  Premis Desc     986291 non-null  object \n",
      " 16  Weapon Used Cd  325035 non-null  float64\n",
      " 17  Weapon Desc     325035 non-null  object \n",
      " 18  Status          986872 non-null  object \n",
      " 19  Status Desc     986873 non-null  object \n",
      " 20  Crm Cd 1        986862 non-null  float64\n",
      " 21  Crm Cd 2        68634 non-null   float64\n",
      " 22  Crm Cd 3        2296 non-null    float64\n",
      " 23  Crm Cd 4        60 non-null      float64\n",
      " 24  LOCATION        986873 non-null  object \n",
      " 25  Cross Street    151963 non-null  object \n",
      " 26  LAT             986873 non-null  float64\n",
      " 27  LON             986873 non-null  float64\n",
      "dtypes: float64(8), int64(7), object(13)\n",
      "memory usage: 210.8+ MB\n",
      "crime_data info:None\n"
     ]
    }
   ],
   "source": [
    "def load_crime_data(url):\n",
    "          \n",
    "           #loading the data \n",
    "          crime_df=pd.read_csv(url)\n",
    "\n",
    "          #Dispplaying the dataSet\n",
    "          crime_data=crime_df.head()\n",
    "          print(f\"crime_dataset:\\n {crime_data}\\n\")\n",
    "          \n",
    "          #Displaying the shape of dataset\n",
    "          crime_shape=crime_df.shape\n",
    "          print(f\"crime_data shape:\\n{crime_shape}\\n\")\n",
    "\n",
    "          #Displaying the info of dataset\n",
    "          print(f\"crime_data info:{crime_df.info()}\")\n",
    "\n",
    "url = \"/Users/deepakbajare/Documents/Projects/Dap/Crime_Data_from_2020_to_Present.csv\"\n",
    "\n",
    "load_crime_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found: True\n",
      "Duplicates removed.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_crime_data(crime_df):\n",
    "\n",
    "\n",
    "     # Checking for duplicate values\n",
    "    has_duplicates = crime_df.duplicated().any()\n",
    "    print(f\"Duplicates found: {has_duplicates}\")\n",
    "    if has_duplicates:\n",
    "        crime_df = crime_df.drop_duplicates()\n",
    "        print(\"Duplicates removed.\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n",
    " \n",
    "    return crime_df\n",
    "\n",
    "\n",
    "crime_df = pd.read_csv(\"Crime_Data_from_2020_to_Present.csv\")\n",
    "processed_crime_data = preprocess_crime_data(crime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'AREA NAME',\n",
       "       'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Crm Cd Desc', 'Mocodes',\n",
       "       'Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Premis Desc',\n",
       "       'Weapon Used Cd', 'Weapon Desc', 'Status', 'Status Desc', 'Crm Cd 1',\n",
       "       'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'LOCATION', 'Cross Street', 'LAT',\n",
       "       'LON'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_crime_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "SQLAlchemy version: 2.0.36\n",
      "Psycopg2 version: 2.9.10 (dt dec pq3 ext lo64)\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import psycopg2\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"SQLAlchemy version: {sqlalchemy.__version__}\")\n",
    "print(f\"Psycopg2 version: {psycopg2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the preprocessing data into postgres sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Quality Data stored in PostgreSQL successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd  # Required for DataFrame operations\n",
    "\n",
    "# PostgreSQL connection URI\n",
    "postgre_connection_string = \"postgresql+psycopg2://postgres:Admin@localhost:5432/myDatabase\"\n",
    "\n",
    "def store_preprocessed_data(preprocessed_air_quality):\n",
    "    \"\"\"\n",
    "    Stores preprocessed air quality data into a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        preprocessed_air_quality (pd.DataFrame): The preprocessed air quality data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        engine = create_engine(postgre_connection_string)\n",
    "\n",
    "        # Define table name\n",
    "        table_name = \"AirQuality_Dataset\"\n",
    "\n",
    "        # Store DataFrame to PostgreSQL\n",
    "        preprocessed_air_quality.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "        print(\"Air Quality Data stored in PostgreSQL successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while storing data: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `processed_airquality_df` is a pandas DataFrame\n",
    "# processed_airquality_df = pd.DataFrame(...)  # Replace with actual DataFrame\n",
    "store_preprocessed_data(processed_airquality_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime Data stored in PostgreSQL successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd  # Import pandas if you are working with DataFrames\n",
    "\n",
    "# PostgreSQL connection URI\n",
    "postgre_connection_string = \"postgresql+psycopg2://postgres:Admin@localhost:5432/myDatabase\"\n",
    "\n",
    "def store_preprocessed_data(preprocess_crime_data):\n",
    "    \"\"\"\n",
    "    Stores preprocessed crime data into a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        preprocess_crime_data (pd.DataFrame): The preprocessed crime data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Establish database connection using a context manager\n",
    "        with create_engine(postgre_connection_string).connect() as conn:\n",
    "            # Define table name\n",
    "            table_name = \"Crime_Dataset\"\n",
    "\n",
    "            # Store DataFrame to PostgreSQL\n",
    "            preprocess_crime_data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "            print(\"Crime Data stored in PostgreSQL successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while storing data: {e}\")\n",
    "\n",
    "# Example of calling the function\n",
    "# Assuming `processed_crime_data` is a pandas DataFrame\n",
    "# processed_crime_data = pd.DataFrame(...)  # Replace with actual DataFrame\n",
    "store_preprocessed_data(processed_crime_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYPD Data stored in PostgreSQL successfully!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd  # Required for DataFrame operations\n",
    "\n",
    "# PostgreSQL connection URI\n",
    "postgre_connection_string = \"postgresql+psycopg2://postgres:Admin@localhost:5432/myDatabase\"\n",
    "\n",
    "def store_preprocessed_data(preprocessed_nypd_data):\n",
    "    \"\"\"\n",
    "    Stores preprocessed NYPD crime data into a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        preprocessed_nypd_data (pd.DataFrame): The preprocessed NYPD crime data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        engine = create_engine(postgre_connection_string)\n",
    "\n",
    "        # Define table name\n",
    "        table_name = \"NYPD_Dataset\"\n",
    "\n",
    "        # Store DataFrame to PostgreSQL\n",
    "        preprocessed_nypd_data.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "        print(\"NYPD Data stored in PostgreSQL successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while storing NYPD data: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# Assuming `processed_nypd_df` is a pandas DataFrame\n",
    "# processed_nypd_df = pd.DataFrame(...)  # Replace with actual DataFrame\n",
    "store_preprocessed_data(processed_nypd_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_crime_data['Vict Age'].fillna(processed_crime_data['Vict Age'].mean(), inplace=True)\n",
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_crime_data['Vict Age'].fillna(processed_crime_data['Vict Age'].mean(), inplace=True)\n",
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_crime_data['Vict Sex'].fillna('U', inplace=True)\n",
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_crime_data['Vict Sex'].fillna('U', inplace=True)\n",
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_crime_data['TIME OCC'] = processed_crime_data['TIME OCC'].astype(int)\n",
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_nypd_df['ARREST_DATE'] = pd.to_datetime(processed_nypd_df['ARREST_DATE'], errors='coerce')\n",
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_nypd_df['Latitude'] = pd.to_numeric(processed_nypd_df['Latitude'], errors='coerce')\n",
      "/var/folders/0k/lnsbmwws7qv_smwfnkk026400000gn/T/ipykernel_45064/1777925879.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_nypd_df['Longitude'] = pd.to_numeric(processed_nypd_df['Longitude'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Preprocess Data\n",
    "processed_airquality_df['data_value'] = processed_airquality_df['data_value'].fillna(0)\n",
    "processed_airquality_df['start_date'] = pd.to_datetime(processed_airquality_df['start_date'], errors='coerce')\n",
    "processed_airquality_df['data_value'] = pd.to_numeric(processed_airquality_df['data_value'], errors='coerce')\n",
    "\n",
    "processed_crime_data['Vict Age'].fillna(processed_crime_data['Vict Age'].mean(), inplace=True)\n",
    "processed_crime_data['Vict Sex'].fillna('U', inplace=True)\n",
    "processed_crime_data['TIME OCC'] = processed_crime_data['TIME OCC'].astype(int)\n",
    "\n",
    "processed_nypd_df['ARREST_DATE'] = pd.to_datetime(processed_nypd_df['ARREST_DATE'], errors='coerce')\n",
    "processed_nypd_df['Latitude'] = pd.to_numeric(processed_nypd_df['Latitude'], errors='coerce')\n",
    "processed_nypd_df['Longitude'] = pd.to_numeric(processed_nypd_df['Longitude'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16413e780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Visualization and Dashboard\n",
    "nest_asyncio.apply()\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Visualizations for Air Quality Data\n",
    "processed_airquality_df['data_value'] = pd.to_numeric(airquality_df['data_value'], errors='coerce')\n",
    "processed_airquality_df = processed_airquality_df.dropna(subset=['data_value'])\n",
    "bins = [0, 10, 20, 30, 40, 50, 100, 150, 200, 300, 400]\n",
    "labels = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-100', '100-150', '150-200', '200-300', '300-400']\n",
    "processed_airquality_df['data_value_bin'] = pd.cut(processed_airquality_df['data_value'], bins=bins, labels=labels)\n",
    "fig1 = px.histogram(processed_airquality_df, x='data_value_bin', title=\"Distribution of Air Quality Data Values (Binned)\", category_orders={\"Data Value Bin\": labels})\n",
    "fig1.update_layout(xaxis_title=\"Data Value Range\", yaxis_title=\"Count\", bargap=0.2)\n",
    "\n",
    "# Aggregate air quality data by date\n",
    "aggregated_airquality = processed_airquality_df.groupby('start_date')['data_value'].mean().reset_index()\n",
    "\n",
    "# Create line plot\n",
    "fig2 = px.line(\n",
    "    aggregated_airquality,\n",
    "    x='start_date',\n",
    "    y='data_value',\n",
    "    title=\"Air Quality Over Time\",\n",
    "    labels={'start_date': 'Date', 'data_value': 'Average Data Value'}\n",
    ")\n",
    "\n",
    "# Visualizations for Crime Data\n",
    "crime_by_area = processed_crime_data.groupby(['AREA NAME']).size().reset_index(name='Count')\n",
    "fig3 = px.bar(crime_by_area, x='AREA NAME', y='Count', title=\"Crime Incidents by Area\")\n",
    "\n",
    "processed_crime_data['Hour'] = processed_crime_data['TIME OCC'] // 100  # Assuming TIME OCC is in HHMM format\n",
    "crime_by_hour = processed_crime_data.groupby('Hour').size().reset_index(name='Count')\n",
    "fig4 = px.line(\n",
    "    crime_by_hour, x='Hour', y='Count', \n",
    "    title=\"Crime Incidents by Hour of the Day\",\n",
    "    labels={'Hour': 'Hour of the Day', 'Count': 'Number of Incidents'}\n",
    ")\n",
    "fig4.update_traces(line=dict(width=2))\n",
    "fig4.update_layout(xaxis=dict(tickmode='linear', tick0=0, dtick=1))\n",
    "\n",
    "# Crime Data Visualization\n",
    "gender_counts = processed_crime_data['Vict Sex'].value_counts().reset_index()\n",
    "gender_counts.columns = ['Gender', 'Count']\n",
    "fig5 = px.bar(gender_counts, x='Gender', y='Count', title=\"Victim Gender Distribution\", labels={'Gender': 'Gender', 'Count': 'Count'})\n",
    "\n",
    "# Visualizations for NYPD Arrest Data\n",
    "fig6 = px.histogram(processed_nypd_df, x='ARREST_BORO', title=\"Arrests by Borough\")\n",
    "\n",
    "fig7 = px.line(\n",
    "    processed_nypd_df.groupby('ARREST_DATE').size().reset_index(name='Count'),\n",
    "    x='ARREST_DATE', y='Count', title=\"Arrest Trends Over Time\"\n",
    ")\n",
    "\n",
    "# Heatmap for Arrest Data\n",
    "heatmap_data = processed_nypd_df.dropna(subset=['Latitude', 'Longitude'])\n",
    "fig8 = px.density_mapbox(\n",
    "    heatmap_data, lat='Latitude', lon='Longitude', radius=10,\n",
    "    mapbox_style='carto-positron', zoom=10,\n",
    "    title=\"Heatmap of Arrest Locations\"\n",
    ")\n",
    "fig8.update_layout(\n",
    "    mapbox_center={\"lat\": heatmap_data['Latitude'].mean(), \"lon\": heatmap_data['Longitude'].mean()},\n",
    "    margin={\"r\": 0, \"t\": 30, \"l\": 0, \"b\": 0},\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Dashboard Layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Data Analysis Dashboard\", style={'text-align': 'center', 'color': 'white'}),\n",
    "    dcc.Tabs([\n",
    "        dcc.Tab(label='Air Quality Data', children=[\n",
    "            html.Div([dcc.Graph(figure=fig1), dcc.Graph(figure=fig2)])\n",
    "        ]),\n",
    "        dcc.Tab(label='Crime Data', children=[\n",
    "            html.Div([dcc.Graph(figure=fig3), dcc.Graph(figure=fig4), dcc.Graph(figure=fig5)])\n",
    "        ]),\n",
    "        dcc.Tab(label='NYPD Arrest Data', children=[\n",
    "            html.Div([dcc.Graph(figure=fig6), dcc.Graph(figure=fig7), dcc.Graph(figure=fig8)])\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Run the Dashboard\n",
    "app.run_server(mode='inline', debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
